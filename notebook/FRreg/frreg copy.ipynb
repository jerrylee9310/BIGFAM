{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys; sys.path.append(\"/data/jerrylee/pjt/BIGFAM.v.2.0\")\n",
    "from src import frreg, tools\n",
    "import importlib\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"UKB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Load relatives phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "info_fn = f\"/data/jerrylee/pjt/BIGFAM.v.2.0/data/{cohort}/relationship_information/relatives.formatted.info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOR</th>\n",
       "      <th>rcode</th>\n",
       "      <th>relationship</th>\n",
       "      <th>volid</th>\n",
       "      <th>relid</th>\n",
       "      <th>volage</th>\n",
       "      <th>relage</th>\n",
       "      <th>volsex</th>\n",
       "      <th>relsex</th>\n",
       "      <th>Erx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SB</td>\n",
       "      <td>daughter-sister</td>\n",
       "      <td>1000094</td>\n",
       "      <td>3653174</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000220</td>\n",
       "      <td>1691267</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000286</td>\n",
       "      <td>1571411</td>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000295</td>\n",
       "      <td>1045127</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000476</td>\n",
       "      <td>3599303</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOR rcode     relationship    volid    relid  volage  relage volsex relsex  \\\n",
       "0    1    SB  daughter-sister  1000094  3653174      65      64      F      F   \n",
       "1    1   NaN              NaN  1000220  1691267      64      64      F      F   \n",
       "2    1   NaN              NaN  1000286  1571411      53      70      F      F   \n",
       "3    1   NaN              NaN  1000295  1045127      60      41      F      F   \n",
       "4    1   NaN              NaN  1000476  3599303      50      51      F      M   \n",
       "\n",
       "    Erx  \n",
       "0  0.75  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relative information format\n",
    "df_pair = pd.read_csv(info_fn, sep='\\t')\n",
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Do FR-reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_path = f\"/data/jerrylee/pjt/BIGFAM.v.2.0/data/{cohort}/phenotype\"\n",
    "frreg_path = f\"/data/jerrylee/pjt/BIGFAM.v.2.0/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno_fns = os.listdir(pheno_path)\n",
    "len(pheno_fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1. DOR level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thred_pair=100\n",
    "n_bootstrap=100\n",
    "std_pheno=True \n",
    "remove_outlier=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_regression(\n",
    "    df_dor, \n",
    "    reg_type=\"intercept\", # intercept or no_intercept\n",
    "    n_bootstrap=100, \n",
    "    progress=True\n",
    "):\n",
    "    slopes = np.zeros(n_bootstrap)\n",
    "    \n",
    "    # volid별로 인덱스를 미리 준비\n",
    "    unique_volids = df_dor['volid'].unique()\n",
    "    vol_to_indices = {vol: df_dor.index[df_dor['volid'] == vol].tolist() \n",
    "                     for vol in unique_volids}\n",
    "    \n",
    "    if progress:\n",
    "        iterator = tqdm(range(n_bootstrap))\n",
    "    else:\n",
    "        iterator = range(n_bootstrap)\n",
    "    \n",
    "    for i in iterator:\n",
    "        # 각 volid마다 하나의 인덱스만 랜덤 선택\n",
    "        selected_indices = np.array([np.random.choice(indices) \n",
    "                                   for indices in vol_to_indices.values()])\n",
    "        \n",
    "        # 첫 번째 필터링된 데이터\n",
    "        df_filtered = df_dor.iloc[selected_indices]\n",
    "        \n",
    "        # 두 번째 resampling\n",
    "        df_resampled = df_filtered.sample(n=len(df_dor), replace=True)\n",
    "        \n",
    "        # statsmodels를 사용한 회귀분석\n",
    "        if reg_type == \"no_intercept\":\n",
    "            model = smf.ols('volpheno ~ 0 + relpheno', data=df_resampled)\n",
    "        else:\n",
    "            model = smf.ols('volpheno ~ relpheno', data=df_resampled)\n",
    "        results = model.fit()\n",
    "        slopes[i] = results.params['relpheno']\n",
    "    \n",
    "    slope_estimate = np.mean(slopes)\n",
    "    slope_se = np.std(slopes)\n",
    "    t_stat = slope_estimate / slope_se\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), len(df_dor)-1))\n",
    "    \n",
    "    return {\n",
    "        'slope': slope_estimate,\n",
    "        'se': slope_se,\n",
    "        'p': p_value,\n",
    "        'n': len(df_dor)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:10<00:00,  1.41it/s]\n",
      "100%|██████████| 100/100 [01:14<00:00,  1.34it/s]\n",
      "  0%|          | 0/106 [02:42<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def std_col(vals):\n",
    "    return (vals - np.mean(vals)) / np.std(vals)\n",
    "\n",
    "for fn in tqdm(pheno_fns):\n",
    "    pheno = fn.split(\".\")[0]\n",
    "    pheno_fn = f\"{pheno_path}/{fn}\"\n",
    "    df_pheno = pd.read_csv(pheno_fn, sep=\"\\t\")\n",
    "    df_pheno = frreg.remove_outliers(df_pheno, \"pheno\")\n",
    "    \n",
    "    if std_pheno:\n",
    "        df_pheno[\"pheno\"] = std_col(df_pheno[\"pheno\"])\n",
    "    \n",
    "    # merge pheno with relatives\n",
    "    df_mrg = frreg.merge_pheno_info(df_pheno, df_pair)\n",
    "    \n",
    "    # unique id set\n",
    "    df = tools.remove_duplicate_relpair(df_mrg, [\"volid\", \"relid\"])\n",
    "    \n",
    "    # flip and concat volid and relid\n",
    "    colns_to_flip = {\"volid\": \"relid\", \n",
    "                     \"volage\": \"relage\", \n",
    "                     \"volsex\": \"relsex\",\n",
    "                     \"volpheno\": \"relpheno\"}\n",
    "    df = (tools.flip_and_concat(df.copy(), colns_to_flip)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    # regression by each DOR\n",
    "    df_no_intercept = pd.DataFrame(columns=[\"DOR\", \"slope\", \"se\", \"p\", \"n\"])\n",
    "    df_intercept = pd.DataFrame(columns=[\"DOR\", \"slope\", \"se\", \"p\", \"n\"])\n",
    "    \n",
    "    for d in sorted(df[\"DOR\"].unique()):\n",
    "        df_dor = df[df[\"DOR\"] == d].copy().reset_index(drop=True)\n",
    "        \n",
    "        if len(df_dor) < thred_pair: # < 5 relative pairs\n",
    "            raise Exception(\"Too small pairs..\")\n",
    "        \n",
    "        # with intercept\n",
    "        results_no_intercept = bootstrap_regression(\n",
    "            df_dor, \n",
    "            reg_type=\"no_intercept\",\n",
    "            n_bootstrap=n_bootstrap,\n",
    "            progress=True\n",
    "        )\n",
    "        \n",
    "        tmp_no_intercept = pd.DataFrame(results_no_intercept, index=[0])\n",
    "        tmp_no_intercept[\"DOR\"] = d\n",
    "        df_no_intercept = (pd.concat([df_no_intercept, tmp_no_intercept])\n",
    "                           .reset_index(drop=True))\n",
    "    \n",
    "        # without intercept\n",
    "        results_intercept = bootstrap_regression(\n",
    "            df_dor, \n",
    "            reg_type=\"intercept\",\n",
    "            n_bootstrap=n_bootstrap,\n",
    "            progress=True\n",
    "        )\n",
    "        tmp_intercept = pd.DataFrame(results_intercept, index=[0])\n",
    "        tmp_intercept[\"DOR\"] = d\n",
    "        df_intercept = (pd.concat([df_intercept, tmp_intercept])\n",
    "                        .reset_index(drop=True))    \n",
    "    \n",
    "    df_no_intercept.to_csv(\n",
    "            f\"{frreg_path}/{pheno}.no_intercept.frreg\",\n",
    "            sep='\\t',\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "    df_intercept.to_csv(\n",
    "            f\"{frreg_path}/{pheno}.intercept.frreg\",\n",
    "            sep='\\t',\n",
    "            index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2. REL level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106 [00:00<?, ?it/s]/tmp/ipykernel_237234/2111081117.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_intercept = (pd.concat([df_intercept, tmp_intercept])\n",
      "  0%|          | 0/106 [01:15<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def std_col(vals):\n",
    "    return (vals - np.mean(vals)) / np.std(vals)\n",
    "\n",
    "for fn in tqdm(pheno_fns):\n",
    "    pheno = fn.split(\".\")[0]\n",
    "    pheno_fn = f\"{pheno_path}/{fn}\"\n",
    "    df_pheno = pd.read_csv(pheno_fn, sep=\"\\t\", names=[\"eid\", \"iid\", \"pheno\"])\n",
    "    df_pheno = frreg.remove_outliers(df_pheno[[\"eid\", \"pheno\"]], \"pheno\")\n",
    "    \n",
    "    if std_pheno:\n",
    "        df_pheno[\"pheno\"] = std_col(df_pheno[\"pheno\"])\n",
    "    \n",
    "    # merge pheno with relatives\n",
    "    df_mrg = frreg.merge_pheno_info(df_pheno, df_pair)\n",
    "    \n",
    "    # unique id set\n",
    "    df = tools.remove_duplicate_relpair(df_mrg, [\"volid\", \"relid\"])\n",
    "    \n",
    "    # flip and concat volid and relid\n",
    "    colns_to_flip = {\"volid\": \"relid\", \n",
    "                     \"volage\": \"relage\", \n",
    "                     \"volsex\": \"relsex\",\n",
    "                     \"volpheno\": \"relpheno\"}\n",
    "    df = (tools.flip_and_concat(df.copy(), colns_to_flip)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    # regression by each DOR\n",
    "    df_intercept = pd.DataFrame(columns=[\"DOR\", \"relationship\", \"slope\", \"se\", \"p\", \"n\"])\n",
    "    \n",
    "    for rel in df[\"relationship\"].unique():\n",
    "        df_rel = df[df[\"relationship\"] == rel].copy().reset_index(drop=True)\n",
    "        \n",
    "        if len(df_rel) < thred_pair: # < 100 relative pairs\n",
    "            continue\n",
    "        \n",
    "        results_intercept = bootstrap_regression(\n",
    "            df_rel, \n",
    "            reg_type=\"intercept\",\n",
    "            n_bootstrap=n_bootstrap,\n",
    "            progress=False\n",
    "        )\n",
    "        tmp_intercept = pd.DataFrame(results_intercept, index=[0])\n",
    "        tmp_intercept[\"DOR\"] = df_rel[\"DOR\"].unique()[0]\n",
    "        tmp_intercept[\"relationship\"] = rel\n",
    "\n",
    "        df_intercept = (pd.concat([df_intercept, tmp_intercept])\n",
    "                        .reset_index(drop=True))    \n",
    "        \n",
    "    df_intercept.to_csv(\n",
    "            f\"{frreg_path}/{cohort}.{pheno}.REL.frreg\",\n",
    "            sep='\\t',\n",
    "            index=False\n",
    "        )\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. PO-SIB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/jerrylee/pjt/BIGFAM.v.2.0/data/GS/po-sib'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = f\"/data/jerrylee/pjt/BIGFAM.v.2.0/data/{cohort}/po-sib\"\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "subgroups = [\"PC\", \"SB\"]\n",
    "\n",
    "for fn in tqdm(pheno_fns):\n",
    "    pheno = fn.split(\".\")[0]\n",
    "    pheno_fn = f\"{pheno_path}/{fn}\"\n",
    "    df_pheno = pd.read_csv(pheno_fn, sep=\"\\t\")\n",
    "    df_pheno = frreg.remove_outliers(df_pheno, \"pheno\")\n",
    "    \n",
    "    for subgroup in subgroups:\n",
    "        # DOR=1인 데이터 중 rcode=\"SB\"만 남기고, 나머지 DOR은 유지\n",
    "        df_pair_filtered = pd.concat([\n",
    "            # DOR=1이면서 rcode=\"SB\"인 데이터\n",
    "            df_pair[(df_pair[\"DOR\"] == 1) & (df_pair[\"rcode\"] == subgroup)],\n",
    "            # DOR이 1이 아닌 모든 데이터\n",
    "            df_pair[df_pair[\"DOR\"] != 1]\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "        # merge pheno with relatives\n",
    "        df_mrg = frreg.merge_pheno_info(df_pheno, df_pair_filtered)\n",
    "        break\n",
    "        try:\n",
    "            df_frreg, msgs = frreg.familial_relationship_regression_DOR(\n",
    "                df_mrg.drop(columns=[\"rcode\", \"relationship\", \"Erx\"]),\n",
    "                n_bootstrap=100\n",
    "            )\n",
    "            \n",
    "            df_frreg.to_csv(\n",
    "                f\"{output_path}/{pheno}.{subgroup}.frreg\",\n",
    "                sep='\\t',\n",
    "                index=False\n",
    "            )\n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SB', 'PC'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair.loc[df_pair[\"DOR\"] == 1][\"rcode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOR</th>\n",
       "      <th>slope</th>\n",
       "      <th>se</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.189230</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.092695</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.045820</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOR     slope        se    p      n\n",
       "0    1  0.189230  0.008803  0.0   8724\n",
       "1    2  0.092695  0.007556  0.0  17450\n",
       "2    3  0.045820  0.003846  0.0  82132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIGFAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
